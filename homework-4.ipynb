{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed88cc12-1070-40ad-b2bc-aa40135b8966",
   "metadata": {},
   "source": [
    "# Homework: Evaluation and Monitoring\n",
    "\n",
    "In this homework, we'll evaluate the quality of our RAG system.\n",
    "\n",
    "> It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "\n",
    "## Getting the data\n",
    "\n",
    "Let's start by getting the dataset. We will use the data we generated in the module.\n",
    "\n",
    "In particular, we'll evaluate the quality of our RAG system with [gpt-4o-mini](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv)\n",
    "\n",
    "Read it:\n",
    "\n",
    "```python\n",
    "url = f'{github_url}?raw=1'\n",
    "df = pd.read_csv(url)\n",
    "```\n",
    "\n",
    "We will use only the first 300 documents:\n",
    "\n",
    "```python\n",
    "df = df.iloc[:300]\n",
    "```\n",
    "\n",
    "## Q1. Getting the embeddings model\n",
    "\n",
    "Now, get the embeddings model `multi-qa-mpnet-base-dot-v1` from [the Sentence Transformer library](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#model-overview)\n",
    "\n",
    "> Note: this is not the same model as in HW3\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "```\n",
    "\n",
    "Create the embeddings for the first LLM answer:\n",
    "\n",
    "```python\n",
    "answer_llm = df.iloc[0].answer_llm\n",
    "```\n",
    "\n",
    "What's the first value of the resulting vector?\n",
    "\n",
    "* -0.42\n",
    "* -0.22\n",
    "* -0.02\n",
    "* 0.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52bdccc1-c0e8-4fcd-b65b-d0f6cc3e73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb552c3-ea30-42bf-889f-07792e5c98c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "1  You can sign up using the link provided in the...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3  The context does not provide any specific info...   \n",
       "4  To structure your questions and answers for th...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv'\n",
    "url = f'{github_url}?raw=1'\n",
    "df = pd.read_csv(url).iloc[:300]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1274ec4-9030-4eac-9ded-b518a17e8eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaolang/.local/pyenvs/llm/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae2fe101-1f97-48ab-9522-7b555cbee2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First value in vector: -0.42\n"
     ]
    }
   ],
   "source": [
    "answer_llm = df.iloc[0].answer_llm\n",
    "embedding = embedding_model.encode(answer_llm)\n",
    "print(f'First value in vector: {embedding[0]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eebdf0-0e38-41b3-bd7e-581fe96acaf3",
   "metadata": {},
   "source": [
    "## Q2. Computing the dot product\n",
    "\n",
    "Now for each answer pair, let's create embeddings and compute dot product between them\n",
    "\n",
    "We will put the results (scores) into the `evaluations` list\n",
    "\n",
    "What's the 75% percentile of the score?\n",
    "\n",
    "* 21.67\n",
    "* 31.67\n",
    "* 41.67\n",
    "* 51.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f1d1cc-9cdb-4ff3-b17b-583bce615f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621cbdca41d34ff98d77771ced691a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LLM embeddings:   0%|          | 0/300 [00:00<?, ?embedding/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8c2066ceb943ada1cdedade5681df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Orig. embeddings:   0%|          | 0/300 [00:00<?, ?embedding/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18c686d42484a27a59966ff3a71b236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating dot product: 0pair [00:00, ?pair/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "31.754608"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_embeddings = [embedding_model.encode(ans) for ans in tqdm(df['answer_llm'], desc='LLM embeddings', unit='embedding')]\n",
    "orig_embeddings = [embedding_model.encode(ans) for ans in tqdm(df['answer_orig'], desc='Orig. embeddings', unit='embedding')]\n",
    "results = sorted([x.dot(y) for x, y in tqdm(zip(llm_embeddings, orig_embeddings), desc='Calculating dot product', unit='pair')])\n",
    "seventy_fifth_percentile = int(len(results) * 0.75)\n",
    "results[seventy_fifth_percentile]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dd7b2e-2650-4c9b-9ba3-b704678c283a",
   "metadata": {},
   "source": [
    "## Q3. Computing the cosine\n",
    "\n",
    "From Q2, we can see that the results are not within the [0, 1] range. It's because the vectors coming from this model are not normalized.\n",
    "\n",
    "So we need to normalize them.\n",
    "\n",
    "To do it, we\n",
    "\n",
    "* Compute the norm of a vector\n",
    "* Divide each element by this norm\n",
    "\n",
    "So, for vector `v`, it'll be `v / ||v||`\n",
    "\n",
    "In numpy, this is how you do it:\n",
    "\n",
    "```python\n",
    "norm = np.sqrt((v * v).sum())\n",
    "v_norm = v / norm\n",
    "```\n",
    "\n",
    "Let's put it into a function and then compute dot product between normalized vectors. This will give us cosine similarity\n",
    "\n",
    "What's the 75% cosine in the scores?\n",
    "\n",
    "* 0.63\n",
    "* 0.73\n",
    "* 0.83\n",
    "* 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f18f49-bbf3-4b25-b92f-3729553a220b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a540494d174a4322b2117d561a55c946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalizing LLM embeddings:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad6cd9cd0774309a8cd9b26bcf8d237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalizing Orig. embeddings:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb81e71cb2034c1cb6392d64040b7d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating dot product: 0pair [00:00, ?pair/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.83714414"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_norm_embeddings = [v / np.sqrt((v * v).sum()) for v in tqdm(llm_embeddings, desc='Normalizing LLM embeddings')]\n",
    "orig_norm_embeddings = [v / np.sqrt((v * v).sum()) for v in tqdm(orig_embeddings, desc='Normalizing Orig. embeddings')]\n",
    "results = sorted([x.dot(y) for x, y in tqdm(zip(llm_norm_embeddings, orig_norm_embeddings), desc='Calculating dot product', unit='pair')])\n",
    "results[seventy_fifth_percentile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824c7c7-9d00-4e09-9ee2-d868c16ec8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
