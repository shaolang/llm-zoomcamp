{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3d0a2e5-13b5-49c7-879b-f2de4203ace0",
   "metadata": {},
   "source": [
    "In the workshop, we extracted contents from two pages in notion titled \"Workshop: Benefits and Perks\" and \"Workshop: Working hours, PTO, and Vacation\".\n",
    "\n",
    "Repeat the same process for a third page titled \"Homework: Employee handbook\" (hidden from public view, but accessible via API key):\n",
    "\n",
    "* Modify the REST API source to extract only this page.\n",
    "* Write the output into a separate table called \"homework\".\n",
    "* Remember to update the table name in all cells where you connect to a lancedb table.\n",
    "\n",
    "To do this you can use the workshop Colab as a basis.\n",
    "\n",
    "Now, answer the following questions:\n",
    "\n",
    "## Q1. Rows in LanceDB\n",
    "\n",
    "How many rows does the lancedb table \"notion_pages__homework\" have?\n",
    "\n",
    "* 14\n",
    "* 15\n",
    "* 16\n",
    "* 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd90154-0a83-4c65-be29-ceaa10ad3ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/shaolang/.local/pyenvs/llm/lib/python3.11/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86393bf2-d302-48c9-9ad4-ee9b6648bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['DESTINATION__LANCEDB__EMBEDDING_MODEL_PROVIDER'] = 'sentence-transformers'\n",
    "os.environ['DESTINATION__LANCEDB__EMBEDDING_MODEL'] = 'all-MiniLM-L6-v2'\n",
    "os.environ['DESTINATION__LANCEDB__CREDENTIALS__URI'] = '.lancedb'\n",
    "os.environ['DESTINATION__LANCEDB__CREDENTIALS__API_KEY'] = 'api_key'\n",
    "os.environ['DESTINATION__LANCEDB__CREDENTIALS__EMBEDDING_MODEL_PROVIDER_API_KEY'] = 'embedding_model_provider_api_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1536b88a-5cb2-4215-a2f4-ed21a3b05991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up the init scripts in \u001b[1mhttps://github.com/dlt-hub/verified-sources.git\u001b[0m...\n",
      "No files to update, exiting\n",
      "yes: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!yes | dlt init rest_api lancedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "326a82b4-444c-4355-939a-e70988c9a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from rest_api import RESTAPIConfig, rest_api_source\n",
    "from dlt.sources.helpers.rest_client.paginators import BasePaginator, JSONResponsePaginator\n",
    "from dlt.sources.helpers.requests import Response, Request\n",
    "from dlt.destinations.adapters import lancedb_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec5dda7a-39db-4315-8818-be14037f6a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline company_policies load step completed in ---\n",
      "0 load package(s) were loaded to destination LanceDB and into dataset None\n",
      "The LanceDB destination used <dlt.destinations.impl.lancedb.configuration.LanceDBCredentials object at 0x3324e2510> location to store data\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "class PostBodyPaginator(BasePaginator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cursor = None\n",
    "\n",
    "    def update_state(self, response: Response) -> None:\n",
    "        # Assuming the API returns an empty list when no more data is available\n",
    "        if not response.json():\n",
    "            self._has_next_page = False\n",
    "        else:\n",
    "            self.cursor = response.json().get(\"next_cursor\")\n",
    "            if self.cursor is None:\n",
    "                self._has_next_page = False\n",
    "\n",
    "    def update_request(self, request: Request) -> None:\n",
    "        if request.json is None:\n",
    "            request.json = {}\n",
    "\n",
    "        # Add the cursor to the request body\n",
    "        request.json[\"start_cursor\"] = self.cursor\n",
    "\n",
    "@dlt.resource(name=\"employee_handbook\")\n",
    "def rest_api_notion_resource():\n",
    "    notion_config: RESTAPIConfig = {\n",
    "        \"client\": {\n",
    "            \"base_url\": \"https://api.notion.com/v1/\",\n",
    "            \"auth\": {\n",
    "                \"token\": dlt.secrets[\"sources.rest_api.notion.api_key\"]\n",
    "            },\n",
    "            \"headers\":{\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Notion-Version\": \"2022-06-28\"\n",
    "            }\n",
    "        },\n",
    "        \"resources\": [\n",
    "            {\n",
    "                \"name\": \"search\",\n",
    "                \"endpoint\": {\n",
    "                    \"path\": \"search\",\n",
    "                    \"method\": \"POST\",\n",
    "                    \"paginator\": PostBodyPaginator(),\n",
    "                    \"json\": {\n",
    "                        \"query\": \"homework\",\n",
    "                        \"sort\": {\n",
    "                            \"direction\": \"ascending\",\n",
    "                            \"timestamp\": \"last_edited_time\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"data_selector\": \"results\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"page_content\",\n",
    "                \"endpoint\": {\n",
    "                    \"path\": \"blocks/{page_id}/children\",\n",
    "                    \"paginator\": JSONResponsePaginator(),\n",
    "                    \"params\": {\n",
    "                        \"page_id\": {\n",
    "                            \"type\": \"resolve\",\n",
    "                            \"resource\": \"search\",\n",
    "                            \"field\": \"id\"\n",
    "                        }\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    yield from rest_api_source(notion_config,name=\"homework\")\n",
    "\n",
    "def extract_page_content(response):\n",
    "    block_id = response[\"id\"]\n",
    "    last_edited_time = response[\"last_edited_time\"]\n",
    "    block_type = response.get(\"type\", \"Not paragraph\")\n",
    "    if block_type != \"paragraph\":\n",
    "        content = \"\"\n",
    "    else:\n",
    "        try:\n",
    "            content = response[\"paragraph\"][\"rich_text\"][0][\"plain_text\"]\n",
    "        except IndexError:\n",
    "            content = \"\"\n",
    "    return {\n",
    "        \"block_id\": block_id,\n",
    "        \"block_type\": block_type,\n",
    "        \"content\": content,\n",
    "        \"last_edited_time\": last_edited_time,\n",
    "        \"inserted_at_time\": datetime.now(timezone.utc)\n",
    "    }\n",
    "\n",
    "@dlt.resource(\n",
    "    name=\"homework\",\n",
    "    write_disposition=\"merge\",\n",
    "    primary_key=\"block_id\",\n",
    "    columns={\"last_edited_time\":{\"dedup_sort\":\"desc\"}}\n",
    "    )\n",
    "def rest_api_notion_incremental(\n",
    "    last_edited_time = dlt.sources.incremental(\"last_edited_time\", initial_value=\"2024-06-26T08:16:00.000Z\",primary_key=(\"block_id\"))\n",
    "):\n",
    "    # last_value = last_edited_time.last_value\n",
    "    # print(last_value)\n",
    "\n",
    "    for block in rest_api_notion_resource.add_map(extract_page_content):\n",
    "        if not(len(block[\"content\"])):\n",
    "            continue\n",
    "        yield block\n",
    "\n",
    "def load_notion() -> None:\n",
    "    pipeline = dlt.pipeline(\n",
    "        pipeline_name=\"company_policies\",\n",
    "        destination=\"lancedb\",\n",
    "        dataset_name=\"notion_pages\",\n",
    "        # full_refresh=True\n",
    "    )\n",
    "\n",
    "    load_info = pipeline.run(\n",
    "        lancedb_adapter(\n",
    "            rest_api_notion_incremental,\n",
    "            embed=\"content\"\n",
    "        ),\n",
    "        table_name=\"homework\",\n",
    "        write_disposition=\"merge\"\n",
    "    )\n",
    "    print(load_info)\n",
    "\n",
    "load_notion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bd900cc-b82b-42b0-8c6d-6453e01753cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lancedb\n",
    "\n",
    "db = lancedb.connect('.lancedb')\n",
    "dbtable = db.open_table('notion_pages___homework')\n",
    "df = dbtable.to_pandas()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087be21d-29e7-445c-b097-4269f98abcf0",
   "metadata": {},
   "source": [
    "Answer: 17 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad10684-313b-45d3-8555-781f44c39a8c",
   "metadata": {},
   "source": [
    "## Q2. Running the Pipeline: Last edited time\n",
    "\n",
    "In the demo, we created an incremental dlt resource rest_api_notion_incremental that keeps track of last_edited_time. What value does it store after you've run your pipeline once? (Hint: you will be able to get this value by performing some aggregation function on the column last_edited_time of the table)\n",
    "\n",
    "* Timestamp('2024-07-05 22:34:00+0000', tz='UTC') (OR \"2024-07-05T22:34:00.000Z\")\n",
    "* Timestamp('2024-07-05 23:33:00+0000', tz='UTC') (OR \"2024-07-05T23:33:00.000Z\")\n",
    "* Timestamp('2024-07-05 23:52:00+0000', tz='UTC') (OR \"2024-07-05T23:52:00.000Z\")\n",
    "* Timestamp('2024-07-05 22:56:00+0000', tz='UTC') (OR \"2024-07-05T22:56:00.000Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f74c83-fffc-4b78-8e40-3b503b808076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-07-05 23:33:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['last_edited_time'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263c509-febf-42ba-b1d2-3618eb708fc6",
   "metadata": {},
   "source": [
    "## Q3. Ask the Assistant\n",
    "\n",
    "Find out with the help of the AI assistant: how many PTO days are the employees entitled to in a year?\n",
    "\n",
    "* 20\n",
    "* 25\n",
    "* 30\n",
    "* 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1c37c9f-f900-4665-ba67-9ea68a6518fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a46522cc-d9c9-4662-bb43-b93159a6eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context_from_lancedb(dbtable, question, top_k=2):\n",
    "\n",
    "    query_results = dbtable.search(query=question).to_list()\n",
    "    context = \"\\n\".join([result[\"content\"] for result in query_results[:top_k]])\n",
    "\n",
    "    return context\n",
    "\n",
    "def main():\n",
    "  # Connect to the lancedb table\n",
    "  db = lancedb.connect(\".lancedb\")\n",
    "  dbtable = db.open_table(\"notion_pages___homework\")\n",
    "\n",
    "  # A system prompt telling ollama to accept input in the form of \"Question: ... ; Context: ...\"\n",
    "  messages = [\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant that helps users understand policies inside a company's employee handbook. The user will first ask you a question and then provide you relevant paragraphs from the handbook as context. Please answer the question based on the provided context. For any details missing in the paragraph, encourage the employee to contact the HR for that information. Please keep the responses conversational.\"}\n",
    "  ]\n",
    "\n",
    "  while True:\n",
    "    # Accept user question\n",
    "    question = input(\"You: \")\n",
    "\n",
    "    # Retrieve the relevant paragraphs on the question\n",
    "    context = retrieve_context_from_lancedb(dbtable,question,top_k=2)\n",
    "\n",
    "    # Create a user prompt using the question and retrieved context\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": f\"Question: '{question}'; Context:'{context}'\"}\n",
    "    )\n",
    "\n",
    "    # Get the response from the LLM\n",
    "    response = ollama.chat(\n",
    "        model=\"llama2-uncensored\",\n",
    "        messages=messages\n",
    "    )\n",
    "    response_content = response['message']['content']\n",
    "    print(f\"Assistant: {response_content}\")\n",
    "\n",
    "    # Add the response into the context window\n",
    "    messages.append(\n",
    "        {\"role\": \"assistant\", \"content\":response_content}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a54c66-d57b-4928-ad87-3e6eae72b350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  how many PTO days are the employees entitled to in a year?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaolang/.local/pyenvs/llm/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Based on the context provided by the user, it is unclear if they are asking about paid time off or vacation days. However, for the sake of simplicity, let us assume that the question is about PTO days. \n",
      "You can refer to the employee handbook to get more information about the PTO policy. Based on what you have read so far, it seems like employees receive a total of 30 days of paid time off per year, with 2.5 days accrued each month. After your first year at the company, you will earn an additional day of PTO for a total of 25 days overall. It is also mentioned that if you leave the company, any unused PTO will be compensated according to local law, and non-exempt employees will receive premium pay on holidays.\n",
      "If the user needs more clarification or information about their specific situation, they can contact HR for assistance.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
