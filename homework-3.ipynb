{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d0798ec-3023-48a1-94a8-72eef9d0f670",
   "metadata": {},
   "source": [
    "# Homework 3: Vector Search\n",
    "\n",
    "In this homework, we'll experiemnt with vector with and without Elasticsearch\n",
    "\n",
    "> It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "\n",
    "## Q1. Getting the embeddings model\n",
    "\n",
    "First, we will get the embeddings model multi-qa-distilbert-cos-v1 from the Sentence Transformer library\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "```\n",
    "\n",
    "Create the embedding for this user question:\n",
    "\n",
    "```python\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "```\n",
    "\n",
    "What's the first value of the resulting vector?\n",
    "\n",
    "* -0.24\n",
    "* -0.04\n",
    "* 0.07\n",
    "* 0.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2db9e9-56db-4bda-8524-2fd8fea6e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a082a7-2a29-4e08-82ee-76e60f4c9762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First value in embedding: 0.0782226175069809\n"
     ]
    }
   ],
   "source": [
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "user_question = 'I just discovered the course. Can I still join it?'\n",
    "\n",
    "embeddings = embedding_model.encode(user_question)\n",
    "print(f'First value in embedding: {embeddings[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744c7e37-b4bc-4e70-80ce-4205235d60b3",
   "metadata": {},
   "source": [
    "## Prepare the documents\n",
    "\n",
    "Now we will create the embeddings for the documents.\n",
    "\n",
    "Load the documents with ids that we prepared in the module:\n",
    "\n",
    "```\n",
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()\n",
    "```\n",
    "\n",
    "We will use only a subset of the questions - the questions for \"machine-learning-zoomcamp\". After filtering, you should have only 375 documents.\n",
    "\n",
    "## Q2. Creating the embeddings\n",
    "\n",
    "Now for each document, we will create an embedding for both question and answer fields.\n",
    "\n",
    "We want to put all of them into a single matrix X:\n",
    "\n",
    "* Create a list `embeddings`\n",
    "* Iterate over each document\n",
    "* `qa_text = f'{question} {text}'`\n",
    "* compute the embedding for `qa_text`, append to `embeddings`\n",
    "* At the end, let `X = np.array(embeddings)` (`import numpy as np`)\n",
    "\n",
    "What's the shape of X? (`X.shape`). Include the parantheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be8e6cda-df64-4052-a94f-202811a101e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>c02e79ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>1f6520ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, even if you don't register, you're still ...</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I still join the course after the...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>7842b56a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You don't need it. You're accepted. You can al...</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - I have registered for the Data Engine...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>0bbf41ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>63394d91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The purpose of this document is to capture fre...   \n",
       "1  GitHub - DataTalksClub data-engineering-zoomca...   \n",
       "2  Yes, even if you don't register, you're still ...   \n",
       "3  You don't need it. You're accepted. You can al...   \n",
       "4  You can start by installing and setting up all...   \n",
       "\n",
       "                            section  \\\n",
       "0  General course-related questions   \n",
       "1  General course-related questions   \n",
       "2  General course-related questions   \n",
       "3  General course-related questions   \n",
       "4  General course-related questions   \n",
       "\n",
       "                                            question  \\\n",
       "0               Course - When will the course start?   \n",
       "1  Course - What are the prerequisites for this c...   \n",
       "2  Course - Can I still join the course after the...   \n",
       "3  Course - I have registered for the Data Engine...   \n",
       "4   Course - What can I do before the course starts?   \n",
       "\n",
       "                      course        id  \n",
       "0  data-engineering-zoomcamp  c02e79ef  \n",
       "1  data-engineering-zoomcamp  1f6520ca  \n",
       "2  data-engineering-zoomcamp  7842b56a  \n",
       "3  data-engineering-zoomcamp  0bbf41ec  \n",
       "4  data-engineering-zoomcamp  63394d91  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()\n",
    "pd.DataFrame(documents).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a262027b-0852-4e43-adb4-56978de88857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n"
     ]
    }
   ],
   "source": [
    "mlzc_docs = [doc for doc in documents if doc['course'] == 'machine-learning-zoomcamp']\n",
    "print(len(mlzc_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ddbf0ed-abce-4dcb-97cb-9ddb83889385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969e72f7155f451f97e069427953cff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = [embedding_model.encode(f\"{doc['question']} {doc['text']}\") for doc in tqdm(mlzc_docs)]\n",
    "X = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8fdc6cb-f355-46be-8a60-3d898bc1f5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e9bf0-6b0b-44a5-80e7-c24a30c7ef8f",
   "metadata": {},
   "source": [
    "## Q3. Search\n",
    "\n",
    "We have the embeddings and the query vector. Now let's compute the cosine similarity between the vector from Q1 (let's call it v) and the matrix from Q2.\n",
    "\n",
    "The vectors returned from the embedding model are already normalized (you can check it by computing a dot product of a vector with itself - it should return something very close to 1.0). This means that in order to compute the coside similarity, it's sufficient to multiply the matrix X by the vector v:\n",
    "\n",
    "```python\n",
    "scores = X.dot(v)\n",
    "```\n",
    "\n",
    "What's the highest score in the results?\n",
    "\n",
    "* 65.0\n",
    "* 6.5\n",
    "* 0.65\n",
    "* 0.065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db80aea-53dd-4ac5-a725-1788016da437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506574"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = embedding_model.encode(user_question)\n",
    "max(X.dot(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e69cc-6a87-443a-b3e6-90a21c00d6c6",
   "metadata": {},
   "source": [
    "## Vector search\n",
    "\n",
    "We can now compute the similarity between a query vector and all the embeddings.\n",
    "\n",
    "Let's use this to implement our own vector search\n",
    "\n",
    "```python\n",
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "```\n",
    "\n",
    "search_engine = VectorSearchEngine(documents=documents, embeddings=X)\n",
    "search_engine.search(v, num_results=5)\n",
    "\n",
    "If you don't understand how the search function work:\n",
    "\n",
    "\n",
    "* Ask ChatGTP or any other LLM of your choice to explain the code\n",
    "* Check our pre-course workshop about implementing a search engine here\n",
    "\n",
    "(Note: you can replace argsort with argpartition to make it a lot faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5743db51-980d-4166-a300-9bd6869f8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48379c6f-a3ca-4870-8c25-fdf1702ecf34",
   "metadata": {},
   "source": [
    "## Q4. Hit-rate for our search engine\n",
    "\n",
    "Let's evaluate the performance of our own search engine. We will use the hitrate metric for evaluation.\n",
    "\n",
    "First, load the ground truth dataset:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "```\n",
    "\n",
    "Now use the code from the module to calculate the hitrate of VectorSearchEngine with num_results=5.\n",
    "\n",
    "What did you get?\n",
    "\n",
    "* 0.93\n",
    "* 0.73\n",
    "* 0.53\n",
    "* 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a8cea89-8265-4791-9f29-3dbc43c2287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f8a42c5-8e4d-4877-8393-b47dec1724b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0227b872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0227b872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0227b872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0227b872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0227b872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "2123                Where can I sign up for the course?   \n",
       "2124                 Can you provide a link to sign up?   \n",
       "2125  Is there an FAQ for this Machine Learning course?   \n",
       "2126  Does this course have a GitHub repository for ...   \n",
       "2127  How can I structure my questions and answers f...   \n",
       "\n",
       "                         course  document  \n",
       "2123  machine-learning-zoomcamp  0227b872  \n",
       "2124  machine-learning-zoomcamp  0227b872  \n",
       "2125  machine-learning-zoomcamp  0227b872  \n",
       "2126  machine-learning-zoomcamp  0227b872  \n",
       "2127  machine-learning-zoomcamp  0227b872  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e78e0b-84ad-41b8-95e0-d98e00966343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0549215775d4527a4bcb9381fdd50e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit rate: 0.940\n"
     ]
    }
   ],
   "source": [
    "search_engine = VectorSearchEngine(documents=mlzc_docs, embeddings=X)\n",
    "\n",
    "matches = []\n",
    "\n",
    "for m in tqdm(ground_truth):\n",
    "    results = search_engine.search(embedding_model.encode(m['question']), num_results=5)\n",
    "    matches.append(m['document'] in [d['id'] for d in results])\n",
    "\n",
    "hit_rate = sum(matches) / len(ground_truth)\n",
    "print(f'hit rate: {hit_rate:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ca939-438f-416f-b604-1f4abae66aa2",
   "metadata": {},
   "source": [
    "## Q5. Indexing with Elasticsearch\n",
    "\n",
    "Now let's index these documents with elasticsearch\n",
    "\n",
    "* Create the index with the same settings as in the module (but change the dimensions)\n",
    "* Index the embeddings (note: you've already computed them)\n",
    "\n",
    "After indexing, let's perform the search of the same query from Q1.\n",
    "\n",
    "What's the ID of the document with the highest score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2616dc78-3005-4813-83d5-2ca85fbe519d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "index_settings = dict(\n",
    "    settings=dict(number_of_shards=1, number_of_replicas=0),\n",
    "    mappings=dict(\n",
    "        properties=dict(\n",
    "            id=dict(type='text'),\n",
    "            text=dict(type='text'),\n",
    "            section=dict(type='text'),\n",
    "            question=dict(type='text'),\n",
    "            course=dict(type='keyword'),\n",
    "            question_vector=dict(type='dense_vector', index=True, similarity='cosine', dims=X.shape[1]),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "index_name = 'course-questions'\n",
    "\n",
    "es.indices.delete(index=index_name, ignore_unavailable=True)   # clear previously loaded, if any\n",
    "es.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4acf3314-1fb8-41e5-b4f5-c6017c4940bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e506261a30d94933af214b3f22a6aa0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing:   0%|          | 0/375 [00:00<?, ?document/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc, embedding in tqdm(zip(mlzc_docs, X), desc='Indexing', total=len(mlzc_docs), unit='document'):\n",
    "    es.index(index=index_name, document=doc | dict(question_vector=embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96a3fa1c-0eda-42b7-ac81-7b3c7efd160d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of doc with highest score: ee58a693\n"
     ]
    }
   ],
   "source": [
    "knn = dict(\n",
    "    field='question_vector',\n",
    "    query_vector=v,\n",
    "    k=5,\n",
    "    num_candidates=5,\n",
    "    filter=dict(term=dict(course='machine-learning-zoomcamp')),\n",
    ")\n",
    "query_template = dict(knn=knn, _source=['id'])\n",
    "response = es.search(index=index_name, body=query_template)\n",
    "sorted_response = sorted(response['hits']['hits'], key=lambda m: m['_score'], reverse=True)\n",
    "\n",
    "print(f'ID of doc with highest score:', sorted_response[0]['_source']['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc5b548-0825-4ae3-a5e6-efcfb441d46f",
   "metadata": {},
   "source": [
    "## Q6. Hit-rate for Elasticsearch\n",
    "\n",
    "The search engine we used in Q4 computed the similarity between the query and ALL the vectors in our database. Usually this is not practical, as we may have a lot of data.\n",
    "\n",
    "Elasticsearch uses approximate techniques to make it faster.\n",
    "\n",
    "Let's evaluate how worse the results are when we switch from exact search (as in Q4) to approximate search with Elastic.\n",
    "\n",
    "What's hitrate for our dataset for Elastic?\n",
    "\n",
    "* 0.93\n",
    "* 0.73\n",
    "* 0.53\n",
    "* 0.33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d95e8c9-13be-454f-bdcb-e29c37667891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
